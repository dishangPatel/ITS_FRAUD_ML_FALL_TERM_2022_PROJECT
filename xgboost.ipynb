{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as  np\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom xgboost import XGBClassifier\nfrom sklearn import metrics\nfrom hyperopt import fmin,tpe,hp,STATUS_OK,Trials,space_eval","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-03T18:20:45.111279Z","iopub.execute_input":"2022-12-03T18:20:45.111636Z","iopub.status.idle":"2022-12-03T18:20:46.907735Z","shell.execute_reply.started":"2022-12-03T18:20:45.111588Z","shell.execute_reply":"2022-12-03T18:20:46.905996Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def changeDType(df,flag=False):\n    \n    if(flag):\n        numericDtype = ['int32','int64','float64','float32']\n    \n    for i in df.columns:\n        if (df[i].dtype == 'int64' or df[i].dtype == 'int32'):\n            df[i] = pd.to_numeric(df[i],downcast='integer')\n        \n        if (df[i].dtype == 'float64' or df[i].dtype == 'float32'):\n            df[i] = pd.to_numeric(df[i],downcast='float')\n","metadata":{"execution":{"iopub.status.busy":"2022-12-03T18:20:46.909286Z","iopub.execute_input":"2022-12-03T18:20:46.909564Z","iopub.status.idle":"2022-12-03T18:20:46.917578Z","shell.execute_reply.started":"2022-12-03T18:20:46.909541Z","shell.execute_reply":"2022-12-03T18:20:46.915790Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"dfTest = pd.read_csv('../input/preprocessedtestv3/preprocessedTestV3.csv')\ndfTrain = pd.read_csv('../input/preprocessedtrainv3/preprocessedTrainV3.csv')","metadata":{"execution":{"iopub.status.busy":"2022-12-03T18:20:46.919644Z","iopub.execute_input":"2022-12-03T18:20:46.920027Z","iopub.status.idle":"2022-12-03T18:20:58.328381Z","shell.execute_reply.started":"2022-12-03T18:20:46.919995Z","shell.execute_reply":"2022-12-03T18:20:58.327000Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"changeDType(dfTest)\nchangeDType(dfTrain)","metadata":{"execution":{"iopub.status.busy":"2022-12-03T18:20:58.330695Z","iopub.execute_input":"2022-12-03T18:20:58.330982Z","iopub.status.idle":"2022-12-03T18:21:06.479313Z","shell.execute_reply.started":"2022-12-03T18:20:58.330957Z","shell.execute_reply":"2022-12-03T18:21:06.478279Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def evaluateModel(df,model):\n    \n    df = df - df.min()/df.max()-df.min()\n    \n    y_pred = model.predict(df)\n    \n    result = pd.DataFrame(y_pred)\n    \n    result.columns = ['isFraud']\n    result.to_csv(\"./result_xgb_final.csv\")\n    \n    print(\"Result file saved\")\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-03T18:21:06.480709Z","iopub.execute_input":"2022-12-03T18:21:06.480977Z","iopub.status.idle":"2022-12-03T18:21:06.487108Z","shell.execute_reply.started":"2022-12-03T18:21:06.480955Z","shell.execute_reply":"2022-12-03T18:21:06.486088Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def xgbClassifier(df,params=None,splits=5):\n    \n    tmpPara = {'n_estimator':550,'eval_metric':'auc','verbosity':1,'n_jobs':-1,'reg_alpha':8.0,'colsample_bytree':0.8,'learning_rate':0.17500000000000002,'gamma':0.6000000000000001,'reg_lambda':1.20000000000000001,'max_depth':10,'min_child_weight':1.0,'scale_pos_weight':60.0,'subsample':0.700000000000001,'objective':'binary:logistic'}\n    \n    if(params!=None):\n        tmpPara = params\n    \n    X_train = df.drop(['isFraud'],axis=1)\n    Y_train = df['isFraud']\n    \n    X_train = X_train - X_train.min()/X_train.max() - X_train.min()\n    \n    skf = StratifiedKFold(n_splits=splits)\n#     if()\n    xgbc = XGBClassifier(**tmpPara)\n    \n    for trainIndx,testIndx in skf.split(X_train,Y_train):\n        \n        Xtrain = X_train.iloc[trainIndx]\n        Ytrain = Y_train.iloc[trainIndx]\n        \n        Xtest = X_train.iloc[testIndx]\n        Ytest = Y_train.iloc[testIndx]\n    \n        xgbc.fit(Xtrain,Ytrain)\n        \n        print(\"Accuracy : \",xgbc.score(Xtest,Ytest))\n        \n        prob = xgbc.predict_proba(Xtest)[:,1]\n        \n        auc = metrics.roc_auc_score(Ytest,prob)\n        print(\"validation-AUC : \",auc,\"\\n===============================\")\n        \n        \n    return xgbc","metadata":{"execution":{"iopub.status.busy":"2022-12-03T18:21:06.488321Z","iopub.execute_input":"2022-12-03T18:21:06.488564Z","iopub.status.idle":"2022-12-03T18:21:06.503182Z","shell.execute_reply.started":"2022-12-03T18:21:06.488541Z","shell.execute_reply":"2022-12-03T18:21:06.501554Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train,test = train_test_split(dfTrain,test_size=0.25,stratify=dfTrain['isFraud'])\n\nXTrain = train.drop(['isFraud'],axis=1)\nYTrain = train['isFraud']\n\nXTest = test.drop(['isFraud'],axis=1)\nYTest = test['isFraud']\n\n\nXTrain = XTrain - XTrain.min()/XTrain.max()-XTrain.min()\nXTest = XTest - XTest.min()/XTest.max()-XTest.min()\n\n\ndef objectiveFn(paramSpace):\n    \n    xgbc = XGBClassifier(**paramSpace)    \n    xgbc.fit(XTrain,YTrain)\n    \n    prob = xgbc.predict_proba(XTest)[:,1]\n    auc = metrics.roc_auc_score(YTest,prob)\n    print(\"AUC : \",auc)\n    return {'loss':-auc,'status':STATUS_OK} # -ve auc minimization ==> +auc maximization\n","metadata":{"execution":{"iopub.status.busy":"2022-12-03T18:21:06.505381Z","iopub.execute_input":"2022-12-03T18:21:06.505812Z","iopub.status.idle":"2022-12-03T18:21:07.755641Z","shell.execute_reply.started":"2022-12-03T18:21:06.505776Z","shell.execute_reply":"2022-12-03T18:21:07.754670Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"paramSpace = {\n    'n_estimators' : hp.randint('n_estimators',300,800),\n    'max_depth' : hp.randint('max_depth',9,18),\n#     'grow_policy' : hp.randint('grow_policy',0,1),\n    'learning_rate' : hp.quniform('learning_rate',0.01,0.2,0.015),\n    'objective' : 'binary:logistic',\n    'booster':'gbtree',\n    'tree_method' : 'gpu_hist',\n    'n_jobs': -1,\n    'gamma' : hp.quniform('gamma',0.4,1,0.06),\n    'min_child_weight' : hp.quniform('min_child_weight',1,12,1),\n    'subsample':hp.quniform('subsample',0.55,1,0.055),\n    'colsample_bytree':hp.quniform('colsample_bytree', 0.65, 1, 0.055),\n    'reg_alpha' : hp.quniform('reg_alpha', 0, 10, 1),\n    'reg_lambda': hp.quniform('reg_lambda', 1, 2, 0.12),\n    'scale_pos_weight': hp.quniform('scale_pos_weight', 45, 200, 7), # helps in convergence for high imbalance\n    'base_score' : hp.quniform('base_score',0.67,0.72,0.055),\n    'eval_metric'  : 'auc',\n}","metadata":{"execution":{"iopub.status.busy":"2022-12-03T18:21:07.756741Z","iopub.execute_input":"2022-12-03T18:21:07.757094Z","iopub.status.idle":"2022-12-03T18:21:07.764743Z","shell.execute_reply.started":"2022-12-03T18:21:07.757071Z","shell.execute_reply":"2022-12-03T18:21:07.763435Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def tuneParams():\n    trialModels = Trials()\n    \n    bestParam = fmin(fn=objectiveFn,space=paramSpace,algo=tpe.suggest,max_evals=99,trials=trialModels)\n    \n    print(bestParam)\n    return [bestParam,trialModels]","metadata":{"execution":{"iopub.status.busy":"2022-12-03T18:21:07.765752Z","iopub.execute_input":"2022-12-03T18:21:07.766139Z","iopub.status.idle":"2022-12-03T18:21:07.785454Z","shell.execute_reply.started":"2022-12-03T18:21:07.766114Z","shell.execute_reply":"2022-12-03T18:21:07.783402Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# param_models = tuneParams()","metadata":{"execution":{"iopub.status.busy":"2022-11-21T08:36:08.564401Z","iopub.execute_input":"2022-11-21T08:36:08.564865Z","iopub.status.idle":"2022-11-21T10:04:14.935086Z","shell.execute_reply.started":"2022-11-21T08:36:08.564834Z","shell.execute_reply":"2022-11-21T10:04:14.934110Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"AUC :                                                 \n0.9487654493908302                                    \nAUC :                                                                            \n0.9474298110913414                                                               \nAUC :                                                                            \n0.9399103253713272                                                               \nAUC :                                                                            \n0.9495908008097683                                                               \nAUC :                                                                            \n0.9463726409923019                                                               \nAUC :                                                                            \n0.9473695813799765                                                               \nAUC :                                                                              \n0.9514978881842704                                                                 \nAUC :                                                                              \n0.9424393294487955                                                                 \nAUC :                                                                              \n0.9473314377481941                                                                 \nAUC :                                                                              \n0.9481821848369831                                                               \nAUC :                                                                             \n0.9461557601599553                                                                \nAUC :                                                                               \n0.9428995714592743                                                                  \nAUC :                                                                               \n0.9522247358090579                                                                \nAUC :                                                                               \n0.9505648301360525                                                                  \nAUC :                                                                               \n0.9515959945860128                                                                  \nAUC :                                                                               \n0.9499063654103348                                                                  \nAUC :                                                                               \n0.9482156382720458                                                                  \nAUC :                                                                               \n0.9458034615231697                                                                  \nAUC :                                                                               \n0.9492126040251933                                                                  \nAUC :                                                                               \n0.9491829034722341                                                                  \nAUC :                                                                               \n0.9490179904543782                                                                  \nAUC :                                                                               \n0.9507676452097586                                                                  \nAUC :                                                                               \n0.9396308099392128                                                                  \nAUC :                                                                               \n0.9511601952283333                                                                  \nAUC :                                                                               \n0.9503853174767465                                                                  \nAUC :                                                                               \n0.9483060879246237                                                                  \nAUC :                                                                               \n0.9521092552662864                                                                  \nAUC :                                                                               \n0.9496949900934784                                                                  \nAUC :                                                                               \n0.9497715938215139                                                                  \nAUC :                                                                               \n0.9457912003367415                                                                  \nAUC :                                                                               \n0.9522775624259868                                                                  \nAUC :                                                                               \n0.94759670382396                                                                    \nAUC :                                                                               \n0.9515957252288486                                                                  \nAUC :                                                                               \n0.9393763109027359                                                                  \nAUC :                                                                               \n0.9525526219900358                                                                  \nAUC :                                                                               \n0.9519546043940217                                                                  \nAUC :                                                                               \n0.9457468771926187                                                                  \nAUC :                                                                               \n0.9428584479883708                                                                  \nAUC :                                                                               \n0.9493798506665523                                                                  \nAUC :                                                                               \n0.9525466091650884                                                                  \nAUC :                                                                               \n0.9523749453078131                                                                \nAUC :                                                                             \n0.9510253004357873                                                                \nAUC :                                                                             \n0.9481535641284401                                                                \nAUC :                                                                             \n0.9512009986111268                                                                \nAUC :                                                                             \n0.9534455361577543                                                                \nAUC :                                                                             \n0.9503020003535607                                                                \nAUC :                                                                             \n0.9504861657653171                                                                \nAUC :                                                                             \n0.952048469930278                                                                 \nAUC :                                                                             \n0.9508033972398143                                                                \nAUC :                                                                             \n0.9474966225389736                                                                \nAUC :                                                                             \n0.9488428140830517                                                                \nAUC :                                                                             \n0.947339513631601                                                                 \nAUC :                                                                             \n0.9516653800252004                                                                \nAUC :                                                                             \n0.9504573856166588                                                                \nAUC :                                                                             \n0.9512327900037774                                                                \nAUC :                                                                             \n0.9470083371864294                                                                \nAUC :                                                                             \n0.9506483876272905                                                                \nAUC :                                                                             \n0.9483432024429357                                                                \nAUC :                                                                             \n0.9475118261202538                                                                \nAUC :                                                                             \n0.9481881046551967                                                                \nAUC :                                                                             \n0.9524629779931911                                                                \nAUC :                                                                             \n0.9349450449300071                                                                \nAUC :                                                                             \n0.949161398382768                                                                 \nAUC :                                                                             \n0.9495542032639507                                                                \nAUC :                                                                             \n0.9488805953509359                                                                \nAUC :                                                                             \n0.9492739498173641                                                                \nAUC :                                                                             \n0.9489883647899582                                                                \nAUC :                                                                             \n0.9464616774256777                                                                \nAUC :                                                                             \n0.9530056432959072                                                                \nAUC :                                                                             \n0.9536496013869087                                                                \nAUC :                                                                             \n0.9535552031757224                                                                \nAUC :                                                                             \n0.952309312750729                                                                 \nAUC :                                                                             \n0.9541535118707345                                                                  \nAUC :                                                                               \n0.9509318202131424                                                                  \nAUC :                                                                               \n0.9525112509038021                                                                  \nAUC :                                                                               \n0.9532531185121613                                                                  \nAUC :                                                                               \n0.9530002851417355                                                                  \nAUC :                                                                               \n0.9521212265615965                                                                  \nAUC :                                                                               \n0.9503770906083824                                                                  \nAUC :                                                                               \n0.9509466686778025                                                                  \nAUC :                                                                               \n0.954069885530356                                                                   \nAUC :                                                                               \n0.9550626768513985                                                                  \nAUC :                                                                               \n0.9466325464981368                                                                  \nAUC :                                                                               \n0.9544505620918727                                                                  \nAUC :                                                                               \n0.9469363113223049                                                                  \nAUC :                                                                               \n0.9503149874756649                                                                  \nAUC :                                                                               \n0.9536526851036806                                                                  \nAUC :                                                                               \n0.9462419629076488                                                                  \nAUC :                                                                               \n0.9320048423798938                                                                  \nAUC :                                                                               \n0.9505508465132289                                                                  \nAUC :                                                                               \n0.9532157515470004                                                                  \nAUC :                                                                               \n0.9499521368021697                                                                  \nAUC :                                                                               \n0.9532913491112791                                                                  \nAUC :                                                                               \n0.9471748083690463                                                                  \nAUC :                                                                               \n0.9511850014529101                                                                  \nAUC :                                                                               \n0.9479477969968448                                                                  \nAUC :                                                                               \n0.9507692698079013                                                                  \nAUC :                                                                               \n0.9534061302917274                                                                  \nAUC :                                                                               \n0.954906223822681                                                                   \n100%|██████████| 99/99 [1:28:06<00:00, 53.40s/trial, best loss: -0.9550626768513985]\n{'base_score': 0.66, 'colsample_bytree': 0.935, 'gamma': 0.6, 'learning_rate': 0.03, 'max_depth': 15, 'min_child_weight': 10.0, 'n_estimators': 773, 'reg_alpha': 1.0, 'reg_lambda': 2.04, 'scale_pos_weight': 42.0, 'subsample': 0.935}\n","output_type":"stream"}]},{"cell_type":"code","source":"# print(param_models[0])\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-03T16:29:30.659860Z","iopub.execute_input":"2022-12-03T16:29:30.660281Z","iopub.status.idle":"2022-12-03T16:29:30.664583Z","shell.execute_reply.started":"2022-12-03T16:29:30.660250Z","shell.execute_reply":"2022-12-03T16:29:30.663432Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# {'base_score': 0.66, 'colsample_bytree': 0.935, 'gamma': 0.6, 'learning_rate': 0.03, 'max_depth': 15, 'min_child_weight': 10.0,\n# 'n_estimators': 773, 'reg_alpha': 1.0, 'reg_lambda': 2.04, 'scale_pos_weight': 42.0, 'subsample': 0.935}\n# AUC 0.8463\nbest_params = {'objective':'binary:logistic','n_jobs':-1,'base_score': 0.66, 'colsample_bytree': 0.935, 'gamma': 0.6, 'learning_rate': 0.03, 'max_depth': 15, 'min_child_weight': 10.0, 'n_estimators': 773, 'reg_alpha': 1.0, 'reg_lambda': 2.04, 'scale_pos_weight': 42.0, 'subsample': 0.935}\nmodel = xgbClassifier(dfTrain,best_params)\nevaluateModel(dfTest,model)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T10:17:08.682623Z","iopub.execute_input":"2022-11-21T10:17:08.683455Z","iopub.status.idle":"2022-11-21T18:04:51.823704Z","shell.execute_reply.started":"2022-11-21T10:17:08.683412Z","shell.execute_reply":"2022-11-21T18:04:51.822356Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Accuracy :  0.982829391205397\nvalidation-AUC :  0.9639806864407422 \n===============================\nAccuracy :  0.9786840607981793\nvalidation-AUC :  0.9570895847258265 \n===============================\nAccuracy :  0.9775258067138096\nvalidation-AUC :  0.9600860710574438 \n===============================\nAccuracy :  0.9651304559863448\nvalidation-AUC :  0.9464900734649435 \n===============================\nAccuracy :  0.9774445257254328\nvalidation-AUC :  0.9604679046068505 \n===============================\nAccuracy :  0.9801674388360563\nvalidation-AUC :  0.9657926823154163 \n===============================\nAccuracy :  0.9763670724025116\nvalidation-AUC :  0.9551439863972097 \n===============================\nAccuracy :  0.979801263945053\nvalidation-AUC :  0.95609537084803 \n===============================\nAccuracy :  0.9755136046818801\nvalidation-AUC :  0.9599264188058563 \n===============================\nResult file saved\n","output_type":"stream"}]},{"cell_type":"code","source":"# bestParams = {'base_score': 0.6749999999999999, 'colsample_bytree': 0.672, 'gamma': 0.44999999999999996, 'learning_rate': 0.105,\n#               'max_depth': 9, 'min_child_weight': 8.0, 'n_estimators': 671, 'reg_alpha': 4.0, 'reg_lambda': 1.1400000000000001,\n#               'scale_pos_weight': 45.0, 'subsample': 0.8099999999999999,'n_jobs':-1,'verbosity':1}\n\n# model = xgbClassifier(dfTrain,bestParams)\n# evaluateModel(dfTest,model)","metadata":{"execution":{"iopub.status.busy":"2022-11-21T10:04:15.451074Z","iopub.execute_input":"2022-11-21T10:04:15.451382Z","iopub.status.idle":"2022-11-21T10:04:15.461634Z","shell.execute_reply.started":"2022-11-21T10:04:15.451354Z","shell.execute_reply":"2022-11-21T10:04:15.460710Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# n_estimator=550,verbosity=1,n_jobs=-1,reg_alpha=8.0,colsample_bytree=0.8,\n# learning_rate=0.17500000000000002,gamma=0.6000000000000001,\n# reg_lambda=1.20000000000000001,max_depth=10,min_child_weight=1.0,scale_pos_weight=60.0,\n# subsample=0.700000000000001,objective='binary:logistic'\n\n\n# model = xgbClassifier(dfTrain)\n# evaluateModel(dfTest,model)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T06:54:08.666972Z","iopub.execute_input":"2022-11-20T06:54:08.667622Z","iopub.status.idle":"2022-11-20T06:54:08.670717Z","shell.execute_reply.started":"2022-11-20T06:54:08.667596Z","shell.execute_reply":"2022-11-20T06:54:08.670037Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-12-03T16:34:42.869668Z","iopub.execute_input":"2022-12-03T16:34:42.870113Z","iopub.status.idle":"2022-12-03T16:34:42.876116Z","shell.execute_reply.started":"2022-12-03T16:34:42.870070Z","shell.execute_reply":"2022-12-03T16:34:42.875333Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"best_params = {'objective':'binary:logistic','n_jobs':-1,'base_score': 0.66, 'colsample_bytree': 0.935, 'gamma': 0.6, 'learning_rate': 0.03, 'max_depth': 15, 'min_child_weight': 10.0, 'n_estimators': 773, 'reg_alpha': 1.0, 'reg_lambda': 2.04, 'scale_pos_weight': 42.0, 'subsample': 0.935}\nmodel = xgbClassifier(dfTrain,best_params)\nevaluateModel(dfTest,model)","metadata":{"execution":{"iopub.status.busy":"2022-12-03T16:36:17.964850Z","iopub.execute_input":"2022-12-03T16:36:17.965486Z","iopub.status.idle":"2022-12-03T17:32:55.714629Z","shell.execute_reply.started":"2022-12-03T16:36:17.965450Z","shell.execute_reply":"2022-12-03T17:32:55.712701Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Accuracy :  0.9771238140824464\nvalidation-AUC :  0.9428550125332225 \n===============================\nAccuracy :  0.425175658833517\nvalidation-AUC :  0.9131053232629306 \n===============================\nResult file saved\n","output_type":"stream"}]},{"cell_type":"code","source":"# n_estimator=550,verbosity=1,n_jobs=-1,reg_alpha=8.0,colsample_bytree=0.8,\n# learning_rate=0.17500000000000002,gamma=0.6000000000000001,\n# reg_lambda=1.20000000000000001,max_depth=10,min_child_weight=1.0,scale_pos_weight=60.0,\n# subsample=0.700000000000001,objective='binary:logistic'\n\n# v1\nparams = {'n_estimator':550,'verbosity':1,'n_jobs':-1,'reg_alpha':8.0,'colsample_bytree':0.8,'learning_rate':0.17500000000000002,'gamma':0.6000000000000001,'reg_lambda':1.20000000000000001,'max_depth':10,'min_child_weight':1.0,'scale_pos_weight':60.0,'subsample':0.700000000000001,'objective':'binary:logistic'}\nmodel = xgbClassifier(dfTrain,params,7)\nevaluateModel(dfTest,model)\n\n# 0.86854","metadata":{"execution":{"iopub.status.busy":"2022-12-03T18:21:07.787836Z","iopub.execute_input":"2022-12-03T18:21:07.788153Z","iopub.status.idle":"2022-12-03T18:44:08.369575Z","shell.execute_reply.started":"2022-12-03T18:21:07.788124Z","shell.execute_reply":"2022-12-03T18:44:08.368576Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[18:21:10] WARNING: ../src/learner.cc:627: \nParameters: { \"n_estimator\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nAccuracy :  0.979027389249759\nvalidation-AUC :  0.9512300126495153 \n===============================\n[18:24:27] WARNING: ../src/learner.cc:627: \nParameters: { \"n_estimator\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nAccuracy :  0.9154918447338475\nvalidation-AUC :  0.9423773685607336 \n===============================\n[18:27:44] WARNING: ../src/learner.cc:627: \nParameters: { \"n_estimator\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nAccuracy :  0.9190163105323049\nvalidation-AUC :  0.9485867103776785 \n===============================\n[18:31:02] WARNING: ../src/learner.cc:627: \nParameters: { \"n_estimator\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nAccuracy :  0.9210551270704261\nvalidation-AUC :  0.9493009157137986 \n===============================\n[18:34:19] WARNING: ../src/learner.cc:627: \nParameters: { \"n_estimator\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nAccuracy :  0.9239157921355418\nvalidation-AUC :  0.9517970281518575 \n===============================\n[18:37:35] WARNING: ../src/learner.cc:627: \nParameters: { \"n_estimator\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nAccuracy :  0.9089328612972563\nvalidation-AUC :  0.9397593342246329 \n===============================\n[18:40:51] WARNING: ../src/learner.cc:627: \nParameters: { \"n_estimator\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nAccuracy :  0.7150240232646352\nvalidation-AUC :  0.9409919280031783 \n===============================\nResult file saved\n","output_type":"stream"}]},{"cell_type":"code","source":"#v2\nparams = {'n_estimator':500,'verbosity':1,'n_jobs':-1,'reg_alpha':6.0,'colsample_bytree':0.7,'learning_rate':0.2,'gamma':0.7000000000000001,'reg_lambda':1.50000000000000001,'max_depth':15,'min_child_weight':1.0,'scale_pos_weight':45.0,'subsample':0.6500000000000001,'objective':'binary:logistic'}\nmodel = xgbClassifier(dfTrain,params,7)\nevaluateModel(dfTest,model)","metadata":{"execution":{"iopub.status.busy":"2022-12-03T19:02:38.524680Z","iopub.execute_input":"2022-12-03T19:02:38.525024Z","iopub.status.idle":"2022-12-03T19:36:21.568282Z","shell.execute_reply.started":"2022-12-03T19:02:38.525000Z","shell.execute_reply":"2022-12-03T19:36:21.567659Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"[19:02:40] WARNING: ../src/learner.cc:627: \nParameters: { \"n_estimator\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nAccuracy :  0.9820144453400345\nvalidation-AUC :  0.952461824320171 \n===============================\n[19:07:28] WARNING: ../src/learner.cc:627: \nParameters: { \"n_estimator\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nAccuracy :  0.9735586041218864\nvalidation-AUC :  0.944592170957121 \n===============================\n[19:12:16] WARNING: ../src/learner.cc:627: \nParameters: { \"n_estimator\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nAccuracy :  0.9735586041218864\nvalidation-AUC :  0.9518129547799458 \n===============================\n[19:17:05] WARNING: ../src/learner.cc:627: \nParameters: { \"n_estimator\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nAccuracy :  0.9740327475028449\nvalidation-AUC :  0.9507510377903303 \n===============================\n[19:21:53] WARNING: ../src/learner.cc:627: \nParameters: { \"n_estimator\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nAccuracy :  0.980022758882286\nvalidation-AUC :  0.956150301564378 \n===============================\n[19:26:43] WARNING: ../src/learner.cc:627: \nParameters: { \"n_estimator\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nAccuracy :  0.972294221772664\nvalidation-AUC :  0.9469607185289755 \n===============================\n[19:31:31] WARNING: ../src/learner.cc:627: \nParameters: { \"n_estimator\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nAccuracy :  0.9418700214944999\nvalidation-AUC :  0.9459945018587181 \n===============================\nResult file saved\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}